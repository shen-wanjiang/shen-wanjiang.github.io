---
layout:     post
title:      IO常见模型
subtitle:   IO多路复用
date:       2019-04-24
author:     WJ
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - Linux
---

# 常见io模型介绍
- blocking IO
- nonblocking IO
- IO multiplexing
- signal driven IO
- asynchronous IO

#### IO发生时涉及的对象和步骤
- 对于一个network IO(这里我们以read举例),它会涉及到两个系统对象:
    - 一个是调用这个IO的process(or thread)
    - 一个就是系统内核(kernel)

- 当一个read操作发生时,它会经历两个阶段:
    - 等待数据准备,比如accept(),recv()等待操作 `(Waiting for the data to be ready)`
    - 将数据从内核拷贝到进程中,比如accept()接受到请求,recv()接受连接的数据后需要复制到内核,再从内核复制到进程的用户空间 `(Copying the data from the kernel to the process)`
- 对于socket流而言,数据的流向经历两个阶段:
    - 第一步通常涉及到等待网络上的数据分组到达,然后被复制到内核的某个缓冲区
    - 第二步把数据从内核缓冲区复制到应用进程缓冲区
    **记住这两点很重要,因为这些IO模型的区别就是在这两个阶段各有不同的情况**

#### 阻塞I/O (blocking IO)
---
在linux中,默认情况下所有的socket都是blocking, 一个典型的读流程大概是这样的:
![avatar](https://raw.githubusercontent.com/shen-wanjiang/save_picture/master/markdown_pic/Blocking_IO_model.png)
当用户进程调用了recvfrom这个系统调用,kernel就开始了IO的第一个阶段: 准备数据(对于网络IO来说,很多时候数据在一开始还没有到达.比如,还没有收到一个完整的UDP包.这个时候kernel就要等待足够的数据到来). 这个过程需要等待,也就是说数据被拷贝到操作系统内核的缓冲区是需要一个过程的.
而用户进程这边,整个进程会被阻塞(当然,是进程自己选择的阻塞).当kernel一直等到数据准备好了,它就会将数据从kernel拷贝到用户内存,然后kernel返回结果,用户进程才解除block的状态,重新运行起来.
> 所有,blockingIO的特点就是在IO执行的两个阶段都被block了.

#### 非阻塞Ｉ/O(nonblocking IO)
---
linux下，可以通过设置socket使其变为non-blocking. 当对一个non-blocking socket执行读操作时候,流程是这个样子:
![avatar](https://raw.githubusercontent.com/shen-wanjiang/save_picture/master/markdown_pic/non_Blocking_IO_model.png)
当用户进程发出read操作时,如果kernel中的数据还没有准备好,那么它并不会block用户进程,而是立即返回一个error.从用户进程角度来讲,它发起一个read操作后,并不需要等待,而是马上就得到一个结果.用户进程判断结果是一个error时,它就知道数据还没有准备好,于是它可以再次发送read操作.一旦kernel中的数据准备好了,并且又再次收到用户进程的system call, 那么它马上就将数据拷贝到用户内容, 然后返回.
>所以,nonblockingIO的特点是用户进程需要不断的主动询问kernel数据好了没有
**值得注意的是,此时的非阻塞IO只是应用到等待数据上,当真正有数据到达执行的时候,还是同步阻塞IO来的,从途中的 copy data from kernel to user 可以看出**

#### I/O多路复用(IO multiplexing)
---
IOmultiplexing就是我们说的select, poll, epoll, 有些地方这种IO方式为event driven IO.
select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO. 它的基本原理就是select,pollepoll这个function会不断的轮训所负责的所有socket,当某个socket有数据到达了,就通知用户进程.
![avatar](https://raw.githubusercontent.com/shen-wanjiang/save_picture/master/markdown_pic/IO_multiplexing_model.png)
这个图和blockingIO的图其实并没有太大的不同,事实上,还更差一些.因为这里需要使用两个system call(select和recvfrom),而blockingIO只调用了一个system call(recvfrom). 但是,用select的优势在于它可以同时处理多个connection.
>所有,如果处理的连接数不是很高的话,使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好,可能延迟还更大.
>select/epoll的优势并不是对单个连接能处理的更快,而是在于能处理更多的连接
在IOmultiplexing Model中,实际中,对于每一个socket,一般都设置成为non-blocking,因为只有设置成non-blocking才能使用单个线程/进程不被则色(或者说锁住),可以继续处理其它socket>如上图所示,整个用户的process其实是一直被block的.只不过process是被select这个函数block,而不是被socketIO给block.  
当用户进程调用了select,那么整个进程会被block,而同时,所有进来的连接socket,都会加入到select监视列表里面,由kernel会'监视'所有select负责的socket,而之后select(poll, epoll等)函数会不断的轮训所负责的所有socket,这些socket都是非阻塞的存在与select的监视列表,select使用某种监视机制检查某个socket是否有数据到达了,当任何一个socket中的数据准备好了,select就会返回.这个时候用户进程再调用read操作,将数据从kernel拷贝到用户进程.
> I/O多路服用的特点是通过一种机制一个进程能同事等待多个文件描述符,而这些文件描述符(套接字描述符)其中的任意一个进入就读就绪状态,select()函数就可以返回.
所有,IO多路服用,本质上不会有并发的功能,因为任何时候还是只有一个进程或者线程在进行工作,它之所以能提高效率是因为select/epoll把进来的socket放到它们'监视'的列表里面,当任何socket有可读可写数据立马处理.select/epoll手里同事检测着很多socket,一有动静马上返回给进程处理,总比一个一个socket过来,阻塞等待,处理的效率高
当然也可以多线程/多进程方式,一个连接过来开一个进程/线程处理,这样消耗的内存和进程切换会耗掉更多的系统资源.
所以,我们可以结合IO多路复用和多进程/多线程来提高性能并发,IO服用负责提高接受socket的通知效率,收到请求后,交给进程池/线程池来处理逻辑